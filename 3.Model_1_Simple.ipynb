{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook documents and contains code for training and saving traditional classification models on the engineered data\r\n",
    "\r\n",
    "First, lets try logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# necessary imports\r\n",
    "!pip install pandas \r\n",
    "!pip install numpy\r\n",
    "!pip install scikit-learn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "df = pd.read_csv('data/post_FE.csv')\r\n",
    "data = df.to_numpy()\r\n",
    "X = data[:,:-1]\r\n",
    "y = data[:,-1]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\r\n",
    "print(X.shape, y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(303, 18) (303,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def accuracy(y_pred, y_act):\r\n",
    "    return np.sum(y_pred==y_act)/np.shape(y_pred)[0]\r\n",
    "\r\n",
    "model = LogisticRegression(random_state=50, fit_intercept=False, max_iter=500) # We already have intercept in our data\r\n",
    "fit = model.fit(X_train, y_train)\r\n",
    "\r\n",
    "preds = fit.predict(X_test)\r\n",
    "\r\n",
    "print(accuracy(preds, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8032786885245902\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "preds == y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These results are really good! To make sure that the model works well out of the box, lets cross-validate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n",
    "\r\n",
    "model = LogisticRegression(random_state=0, fit_intercept=False, max_iter=500)\r\n",
    "scores = cross_val_score(model, X, y, cv=10)\r\n",
    "\r\n",
    "print(scores)\r\n",
    "print('average test accuracy', np.mean(scores)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.83870968 0.74193548 0.80645161 0.86666667 0.83333333 0.73333333\n",
      " 0.86666667 0.73333333 0.83333333 0.83333333]\n",
      "average test accuracy 0.808709677419355\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the logistic regression model works pretty well for our dataset, or at least OK. Lets summarize the model performance on the test data using cross validation (5-fold)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "print(classification_report(y_test, preds, labels=[0, 1], target_names=['low prob', 'high prob']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low prob       0.84      0.79      0.81        33\n",
      "   high prob       0.77      0.82      0.79        28\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.81      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I want to try Support Vector Machines and classification trees as well before moving on to deep learning models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn import svm\r\n",
    "# trying different kernels and hyperparams\r\n",
    "kernels = ['rbf', 'poly', 'sigmoid']\r\n",
    "\r\n",
    "for kernel in kernels:\r\n",
    "    if kernel == 'poly':\r\n",
    "        for deg in range(5):\r\n",
    "            svm_classifier = svm.SVC(kernel=kernel, degree=deg)\r\n",
    "            scores = cross_val_score(svm_classifier, X, y, cv=10)\r\n",
    "            print('average test accuracy for', kernel, 'of degree', deg, np.mean(scores)) \r\n",
    "    else:\r\n",
    "        svm_classifier = svm.SVC(kernel=kernel)\r\n",
    "        scores = cross_val_score(svm_classifier, X, y, cv=10)\r\n",
    "        print('average test accuracy for', kernel, np.mean(scores)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "average test accuracy for rbf 0.8053763440860214\n",
      "average test accuracy for poly of degree 0 0.5445161290322581\n",
      "average test accuracy for poly of degree 1 0.8218279569892474\n",
      "average test accuracy for poly of degree 2 0.8316129032258065\n",
      "average test accuracy for poly of degree 3 0.8283870967741936\n",
      "average test accuracy for poly of degree 4 0.8218279569892474\n",
      "average test accuracy for sigmoid 0.7759139784946236\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, the 2nd degree polynomial kernel performs best. Lets try with a decision tree instead!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "tree = DecisionTreeClassifier(criterion='gini')\r\n",
    "scores = cross_val_score(tree, X, y, cv=10)\r\n",
    "\r\n",
    "print('average test accuracy', np.mean(scores)) \r\n",
    "\r\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\r\n",
    "scores = cross_val_score(tree, X, y, cv=10)\r\n",
    "\r\n",
    "print('average test accuracy', np.mean(scores)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "average test accuracy 0.7661290322580644\n",
      "average test accuracy 0.7665591397849463\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After testing all these models, it is apparent that the Support Vector Machine with polynomial kernel of degree 2 performs best! So, lets train that model on the FULL dataset and save it in a file for later use"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from pickle import dump\r\n",
    "\r\n",
    "final_model = svm.SVC(kernel='poly', degree=2) # We already have intercept in our data. \r\n",
    "final_fit = final_model.fit(X, y) # fit the model to the WHOLE dataset\r\n",
    "print(X.shape)\r\n",
    "dump(final_fit, open('model/final_simple.sav', 'wb'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(303, 18)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}